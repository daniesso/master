Starting training procedure.
Loading training set...
2019-06-25 21:07:04.895551: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2019-06-25 21:07:04.914872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:04.915387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Quadro P4000 major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:00:05.0
2019-06-25 21:07:04.915603: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-25 21:07:04.917026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-25 21:07:04.918084: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-25 21:07:04.918313: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-25 21:07:04.919613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-25 21:07:04.920708: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-25 21:07:04.924107: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-25 21:07:04.924228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:04.924796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:04.925226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-25 21:07:04.925626: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-06-25 21:07:05.017423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.018036: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30e6950 executing computations on platform CUDA. Devices:
2019-06-25 21:07:05.018052: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Quadro P4000, Compute Capability 6.1
2019-06-25 21:07:05.020665: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600010000 Hz
2019-06-25 21:07:05.021147: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30c4c30 executing computations on platform Host. Devices:
2019-06-25 21:07:05.021162: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-06-25 21:07:05.021311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.021803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: Quadro P4000 major: 6 minor: 1 memoryClockRate(GHz): 1.48
pciBusID: 0000:00:05.0
2019-06-25 21:07:05.021842: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-25 21:07:05.021852: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2019-06-25 21:07:05.021861: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2019-06-25 21:07:05.021879: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2019-06-25 21:07:05.021888: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2019-06-25 21:07:05.021896: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2019-06-25 21:07:05.021905: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-25 21:07:05.021940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.022442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.022908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2019-06-25 21:07:05.022935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2019-06-25 21:07:05.023671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-06-25 21:07:05.023688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2019-06-25 21:07:05.023697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2019-06-25 21:07:05.023788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.024305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-06-25 21:07:05.024912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7629 MB memory) -> physical GPU (device: 0, name: Quadro P4000, pci bus id: 0000:00:05.0, compute capability: 6.1)
Saving vocab defined by training set...
Loading development set...
Writing params file...
Instantiating model...
Ready for training.

Training summery:

=== Data ===

Training set:
Source language:
  Num sentences: 50000 (781 batches)
  Num words: 468799
  Num UNKS: 0 (0.0 per sentence)
  Vocab size: 1385 (original 1381)
  Longest: 30
  Reversed: False

Target language:
  Num sentences: 50000 (781 batches)
  Num words: 468799
  Num UNKS: 0 (0.0 per sentence)
  Vocab size: 1385 (original 1381)
  Longest: 30


Development set:
Source language:
  Num sentences: 256 (4 batches)
  Num words: 2438
  Num UNKS: 0 (0.0 per sentence)
  Vocab size: 1385 (original 1381)
  Longest: 30
  Reversed: False

Target language:
  Num sentences: 256 (4 batches)
  Num words: 2438
  Num UNKS: 0 (0.0 per sentence)
  Vocab size: 1385 (original 1381)
  Longest: 30


=== Model ===
Name: rnnpbnmt
Num layers: 2
Units per layer: 256
Embedding size: 128
Batch size: 64
Learning rate: 0.001
Max translation ratio: 1.5
Gradient clip: 1.0
Dropout: 0
Num PBs: 128
Bind hard: False
Binding strength: 100
Autoencode: False
PB learning rate: 0.01
Sigma: 0
p_reset: 0
Max recog epochs: 100


=== Training ===
Max epochs: 0
Early stopping steps: 20
Warm start: False


==== Starting epoch 1 ====
Initializing epoch state
2019-06-25 21:07:10.535375: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2019-06-25 21:07:11.652812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
WARNING: Logging before flag parsing goes to stderr.
W0625 21:07:11.991420 140139133015872 deprecation.py:323] From /home/paperspace/venv/lib/python3.6/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
  Batch 0 Loss 58.3196
  Batch 100 Loss 36.9442
  Batch 200 Loss 33.8744
  Batch 300 Loss 32.9261
  Batch 400 Loss 28.4715
  Batch 500 Loss 28.3329
  Batch 600 Loss 27.8338
  Batch 700 Loss 30.0660
Finished epoch 1 in 79.0 seconds
Perplexity training: 81.587
Measuring development set...
Recognition iteration 0 Loss 27.756
Recognition finished, iteration 100 Loss 26.232
Recognition iteration 0 Loss 27.072
Recognition finished, iteration 100 Loss 25.534
Recognition iteration 0 Loss 28.903
Recognition finished, iteration 100 Loss 27.360
Recognition iteration 0 Loss 29.470
Recognition finished, iteration 100 Loss 27.721
Perplexity dev: 35.071

==== Starting epoch 2 ====
  Batch 0 Loss 98.6126
  Batch 100 Loss 98.6346
  Batch 200 Loss 150.0750
  Batch 300 Loss 204.5486
  Batch 400 Loss 250.5395
  Batch 500 Loss 310.3399
  Batch 600 Loss 361.8252
  Batch 700 Loss 394.3009
Finished epoch 2 in 74.0 seconds
Perplexity training: 26.766

==== Starting epoch 3 ====
  Batch 0 Loss 393.0476
  Batch 100 Loss 423.1251
  Batch 200 Loss 423.6652
  Batch 300 Loss 359.8931
  Batch 400 Loss 339.2737
  Batch 500 Loss 305.7347
  Batch 600 Loss 261.9041
  Batch 700 Loss 274.0860
Finished epoch 3 in 75.0 seconds
Perplexity training: 20.799
Measuring development set...
Recognition iteration 0 Loss 25.693
Recognition finished, iteration 100 Loss 18.190
Recognition iteration 0 Loss 24.009
Recognition finished, iteration 100 Loss 17.028
Recognition iteration 0 Loss 26.072
Recognition finished, iteration 100 Loss 18.715
Recognition iteration 0 Loss 26.732
Recognition finished, iteration 100 Loss 18.613
Perplexity dev: 159.430

==== Starting epoch 4 ====
  Batch 0 Loss 488.9916
  Batch 100 Loss 512.5471
  Batch 200 Loss 504.1745
  Batch 300 Loss 531.5378
  Batch 400 Loss 547.5840
  Batch 500 Loss 568.6176
  Batch 600 Loss 594.7615
  Batch 700 Loss 622.3696
Finished epoch 4 in 74.0 seconds
Perplexity training: 17.702

==== Starting epoch 5 ====
  Batch 0 Loss 311.9541
  Batch 100 Loss 299.7288
  Batch 200 Loss 395.3647
  Batch 300 Loss 415.2947
  Batch 400 Loss 446.0925
  Batch 500 Loss 454.5795
  Batch 600 Loss 454.6475
  Batch 700 Loss 511.7601
Finished epoch 5 in 74.0 seconds
Perplexity training: 15.499
Measuring development set...
Recognition iteration 0 Loss 25.111
Recognition finished, iteration 100 Loss 15.051
Recognition iteration 0 Loss 23.196
Recognition finished, iteration 100 Loss 13.601
Recognition iteration 0 Loss 25.174
Recognition finished, iteration 100 Loss 15.113
Recognition iteration 0 Loss 26.022
Recognition finished, iteration 100 Loss 15.059
Perplexity dev: 65.347

==== Starting epoch 6 ====
  Batch 0 Loss 273.2038
  Batch 100 Loss 302.2750
  Batch 200 Loss 270.6012
  Batch 300 Loss 282.8493
  Batch 400 Loss 289.2574
  Batch 500 Loss 299.7580
  Batch 600 Loss 308.5378
  Batch 700 Loss 319.3877
Finished epoch 6 in 74.0 seconds
Perplexity training: 13.836

==== Starting epoch 7 ====
  Batch 0 Loss 313.8415
  Batch 100 Loss 332.5568
  Batch 200 Loss 291.1379
  Batch 300 Loss 287.9725
  Batch 400 Loss 286.9734
  Batch 500 Loss 294.2669
  Batch 600 Loss 308.2092
  Batch 700 Loss 315.6324
Finished epoch 7 in 75.0 seconds
Perplexity training: 12.447
Measuring development set...
Recognition iteration 0 Loss 25.258
Recognition finished, iteration 100 Loss 12.471
Recognition iteration 0 Loss 23.164
Recognition finished, iteration 100 Loss 10.693
Recognition iteration 0 Loss 25.321
Recognition finished, iteration 100 Loss 12.274
Recognition iteration 0 Loss 25.930
Recognition finished, iteration 100 Loss 12.270
Perplexity dev: 118.377

==== Starting epoch 8 ====
  Batch 0 Loss 208.4362
  Batch 100 Loss 209.1960
  Batch 200 Loss 257.1428
  Batch 300 Loss 254.2957
  Batch 400 Loss 261.7496
  Batch 500 Loss 249.8527
  Batch 600 Loss 235.5506
  Batch 700 Loss 267.2873
Finished epoch 8 in 75.0 seconds
Perplexity training: 11.299

==== Starting epoch 9 ====
  Batch 0 Loss 181.5600
  Batch 100 Loss 193.5525
  Batch 200 Loss 191.3945
  Batch 300 Loss 216.2878
  Batch 400 Loss 228.4073
  Batch 500 Loss 239.0756
  Batch 600 Loss 242.7840
  Batch 700 Loss 252.8868
Finished epoch 9 in 73.0 seconds
Perplexity training: 10.053
Measuring development set...
Recognition iteration 0 Loss 26.145
Recognition finished, iteration 100 Loss 10.202
Recognition iteration 0 Loss 23.989
Recognition finished, iteration 100 Loss 8.721
Recognition iteration 0 Loss 25.897
Recognition finished, iteration 100 Loss 10.086
Recognition iteration 0 Loss 26.762
Recognition finished, iteration 100 Loss 9.853
Perplexity dev: 73.035

==== Starting epoch 10 ====
  Batch 0 Loss 181.0322
  Batch 100 Loss 194.1750
  Batch 200 Loss 164.8638
  Batch 300 Loss 169.3326
  Batch 400 Loss 175.5019
  Batch 500 Loss 192.2953
  Batch 600 Loss 214.5768
  Batch 700 Loss 224.4528
Finished epoch 10 in 76.0 seconds
Perplexity training: 8.887

==== Starting epoch 11 ====
  Batch 0 Loss 146.5473
  Batch 100 Loss 149.9468
  Batch 200 Loss 162.0671
  Batch 300 Loss 150.9385
  Batch 400 Loss 144.5192
  Batch 500 Loss 129.3578
  Batch 600 Loss 118.4085
  Batch 700 Loss 136.6515
Finished epoch 11 in 76.0 seconds
Perplexity training: 8.019
Measuring development set...
Recognition iteration 0 Loss 28.534
Recognition finished, iteration 100 Loss 8.477
Recognition iteration 0 Loss 26.381
Recognition finished, iteration 100 Loss 7.160
Recognition iteration 0 Loss 27.756
Recognition finished, iteration 100 Loss 8.329
Recognition iteration 0 Loss 29.273
Recognition finished, iteration 100 Loss 8.000
Perplexity dev: 105.271

==== Starting epoch 12 ====
  Batch 0 Loss 129.6085
  Batch 100 Loss 136.9575
  Batch 200 Loss 145.8550
  Batch 300 Loss 164.3864
  Batch 400 Loss 169.1982
  Batch 500 Loss 169.1199
  Batch 600 Loss 165.0294
  Batch 700 Loss 162.3930
Finished epoch 12 in 77.0 seconds
Perplexity training: 7.077

==== Starting epoch 13 ====
  Batch 0 Loss 105.6361
  Batch 100 Loss 115.3718
  Batch 200 Loss 103.3664
  Batch 300 Loss 114.8933
  Batch 400 Loss 126.9322
  Batch 500 Loss 143.1429
  Batch 600 Loss 164.1098
  Batch 700 Loss 176.3250
Finished epoch 13 in 77.0 seconds
Perplexity training: 6.329
Measuring development set...
Recognition iteration 0 Loss 31.482
Recognition finished, iteration 100 Loss 6.916
Recognition iteration 0 Loss 28.754
Recognition finished, iteration 100 Loss 5.783
Recognition iteration 0 Loss 30.125
Recognition finished, iteration 100 Loss 6.858
Recognition iteration 0 Loss 32.016
Recognition finished, iteration 100 Loss 6.479
Perplexity dev: 213.763

==== Starting epoch 14 ====
  Batch 0 Loss 103.8141
  Batch 100 Loss 104.2363
  Batch 200 Loss 100.6688
  Batch 300 Loss 90.2326
  Batch 400 Loss 81.4170
  Batch 500 Loss 73.5439
  Batch 600 Loss 73.2655
  Batch 700 Loss 88.4464
Finished epoch 14 in 79.0 seconds
Perplexity training: 5.689

==== Starting epoch 15 ====
  Batch 0 Loss 93.3734
  Batch 100 Loss 100.8960
  Batch 200 Loss 109.6846
  Batch 300 Loss 117.7226
  Batch 400 Loss 116.8152
  Batch 500 Loss 115.7781
  Batch 600 Loss 112.1315
  Batch 700 Loss 102.7796
Finished epoch 15 in 79.0 seconds
Perplexity training: 5.097
Measuring development set...
Recognition iteration 0 Loss 34.455
Recognition finished, iteration 100 Loss 5.553
Recognition iteration 0 Loss 31.576
Recognition finished, iteration 100 Loss 4.444
Recognition iteration 0 Loss 33.238
Recognition finished, iteration 100 Loss 5.417
Recognition iteration 0 Loss 35.258
Recognition finished, iteration 100 Loss 5.218
Perplexity dev: 313.118

==== Starting epoch 16 ====
  Batch 0 Loss 61.4363
  Batch 100 Loss 68.7975
  Batch 200 Loss 63.9291
  Batch 300 Loss 76.3191
  Batch 400 Loss 90.4134
  Batch 500 Loss 106.9308
  Batch 600 Loss 126.4385
  Batch 700 Loss 132.6047
Finished epoch 16 in 79.0 seconds
Perplexity training: 4.604

==== Starting epoch 17 ====
  Batch 0 Loss 80.1731
  Batch 100 Loss 80.8286
  Batch 200 Loss 76.3857
  Batch 300 Loss 65.0101
  Batch 400 Loss 52.8468
  Batch 500 Loss 48.0719
  Batch 600 Loss 52.8492
  Batch 700 Loss 61.0422
Finished epoch 17 in 79.0 seconds
Perplexity training: 4.173
Measuring development set...
Recognition iteration 0 Loss 37.997
Recognition finished, iteration 100 Loss 4.244
Recognition iteration 0 Loss 35.291
Recognition finished, iteration 100 Loss 3.363
Recognition iteration 0 Loss 36.244
Recognition finished, iteration 100 Loss 4.241
Recognition iteration 0 Loss 38.799
Recognition finished, iteration 100 Loss 3.998
Perplexity dev: 187.676

==== Starting epoch 18 ====
  Batch 0 Loss 61.5873
  Batch 100 Loss 73.3130
  Batch 200 Loss 80.9937
  Batch 300 Loss 81.2147
  Batch 400 Loss 78.3323
  Batch 500 Loss 80.8124
  Batch 600 Loss 81.3671
  Batch 700 Loss 76.9214
Finished epoch 18 in 79.0 seconds
Perplexity training: 3.824

==== Starting epoch 19 ====
  Batch 0 Loss 46.0271
  Batch 100 Loss 43.1135
  Batch 200 Loss 37.5474
  Batch 300 Loss 41.7538
  Batch 400 Loss 52.3494
  Batch 500 Loss 71.1211
  Batch 600 Loss 92.2938
  Batch 700 Loss 96.6590
Finished epoch 19 in 80.0 seconds
Perplexity training: 3.510
Measuring development set...
Recognition iteration 0 Loss 42.563
Recognition finished, iteration 100 Loss 3.238
Recognition iteration 0 Loss 38.374
Recognition finished, iteration 100 Loss 2.477
Recognition iteration 0 Loss 39.590
Recognition finished, iteration 100 Loss 3.128
Recognition iteration 0 Loss 43.094
Recognition finished, iteration 100 Loss 3.126
Perplexity dev: 2231.674

==== Starting epoch 20 ====
  Batch 0 Loss 55.3240
  Batch 100 Loss 61.8767
  Batch 200 Loss 61.7376
  Batch 300 Loss 60.1594
  Batch 400 Loss 48.2163
  Batch 500 Loss 41.0764
  Batch 600 Loss 43.0343
  Batch 700 Loss 42.7797
Finished epoch 20 in 80.0 seconds
Perplexity training: 3.207

==== Starting epoch 21 ====
  Batch 0 Loss 32.2541
  Batch 100 Loss 41.0622
  Batch 200 Loss 54.0906
  Batch 300 Loss 57.4091
  Batch 400 Loss 50.3941
  Batch 500 Loss 49.8959
  Batch 600 Loss 55.3923
  Batch 700 Loss 58.7638
Finished epoch 21 in 79.0 seconds
Perplexity training: 2.963
Measuring development set...
Recognition iteration 0 Loss 47.206
Recognition finished, iteration 100 Loss 2.532
Recognition iteration 0 Loss 42.215
Recognition finished, iteration 100 Loss 1.936
Recognition iteration 0 Loss 43.338
Recognition finished, iteration 100 Loss 2.333
Recognition iteration 0 Loss 48.585
Recognition finished, iteration 100 Loss 2.268
Perplexity dev: 103.244
Finished training in 1770.37 seconds
Finished training after development set stopped improving.
